{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "\n",
    "sys.path.append(nb_dir)\n",
    "sys.path.append(os.path.split(nb_dir)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.xml_document_info import (get_xml_info, get_xml_image_info)\n",
    "from services.get_xml import  create_pdf_processing_paths, extract_pdf_metadata, process_input_pdf\n",
    "from anuvaad_auditor.loghandler import log_info\n",
    "from anuvaad_auditor.loghandler import log_error\n",
    "from src.services import main\n",
    "from src.services.get_underline import get_underline\n",
    "from services import get_xml\n",
    "from src.services.child_text_unify_to_parent import ChildTextUnify\n",
    "from services.preprocess import prepocess_pdf_regions\n",
    "from services.get_tables import page_num_correction , get_text_table_line_df\n",
    "from src.services.ocr_text_utilities import  tesseract_ocr\n",
    "from src.services.get_response import process_image_df,  process_table_df, df_to_json, process_line_df, process_bg_image\n",
    "\n",
    "from utilities.filesystem import (create_directory)\n",
    "import config\n",
    "\n",
    "import src.utilities.app_context as app_context\n",
    "app_context.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(filepath, desired_width, desired_height, df, color=\"green\", save=False):\n",
    "    image  = Image.open(filepath)\n",
    "    image  = image.resize((desired_width, desired_height))\n",
    "    draw   = ImageDraw.Draw(image)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        left   = int(row['text_left'])\n",
    "        right  = int(row['text_width'] + left)\n",
    "        top    = int(row['text_top'])\n",
    "        bottom = int(row[\"text_height\"] + top)\n",
    "        \n",
    "        draw.rectangle(((left, top), (right,bottom)), outline=color)\n",
    "    save_filepath = os.path.join(os.path.dirname(filepath), 'processed_' + os.path.basename(filepath))\n",
    "    if save:\n",
    "        image.save(save_filepath)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def show_df(df):\n",
    "    return df.head(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start of the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  folder structure of test data goes like this\n",
    "  - notebooks\n",
    "      - sample-data\n",
    "          - input\n",
    "          - output\n",
    "          \n",
    "  the pdfs are present in \"input\" directory and they are *.pdf is added into .gitignore\n",
    "  just to save repo size.\n",
    "'''\n",
    "\n",
    "base_dir   = os.getcwd()\n",
    "input_dir  = os.path.join(base_dir, 'sample-data','input')\n",
    "save_dir   = os.path.join(base_dir, 'sample-data', 'bbox_output')\n",
    "output_dir = os.path.join(base_dir, 'sample-data', 'output')\n",
    "\n",
    "#filename   = '6251_2016_3_1501_19387_Judgement_06-Jan-2020.pdf'\n",
    "filename  = 'Madras_HC_02.pdf'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doc_structure_analysis(xml_dfs,img_dfs,working_dir,header_region , footer_region,lang, page_width, page_height, pdf_bg_img_filepaths,pdf_image_paths):\n",
    "    \n",
    "    '''\n",
    "        Document structure analysis to get:\n",
    "            - in_dfs\n",
    "            - table_dfs\n",
    "            - line_dfs\n",
    "            - h_dfs\n",
    "            - v_dfs\n",
    "            - p_dfs\n",
    "            - text_block_dfs\n",
    "\n",
    "    '''\n",
    "    log_info(\"document structure analysis started  ===>\", app_context.application_context)\n",
    "    \n",
    "    text_merger = ChildTextUnify()\n",
    "    \n",
    "    in_dfs, table_dfs, line_dfs,bg_dfs = get_text_table_line_df(xml_dfs, img_dfs, pdf_image_paths)\n",
    "    h_dfs                              = get_xml.get_hdfs(in_dfs,header_region,footer_region)\n",
    "    v_dfs                              = get_xml.get_vdfs(h_dfs)\n",
    "    p_dfs                              = get_xml.get_pdfs(v_dfs)\n",
    "    p_dfs , line_dfs                   = get_underline(p_dfs,line_dfs,app_context.application_context)\n",
    "    p_dfs                              = get_xml.update_font(p_dfs)\n",
    "    \n",
    "    if lang  != 'en':\n",
    "        text_block_dfs  = tesseract_ocr(pdf_image_paths, page_width, page_height, p_dfs, lang)\n",
    "    else:\n",
    "        text_block_dfs  = text_merger.unify_child_text_blocks(p_dfs)\n",
    "\n",
    "    log_info( \"document structure analysis successfully completed\", app_context.application_context )\n",
    "    return text_block_dfs, table_dfs, line_dfs , bg_dfs\n",
    "\n",
    "\n",
    "def doc_structure_response(pages,bg_dfs, text_block_dfs,table_dfs,line_dfs,page_width, page_height,jobid):\n",
    "\n",
    "    '''\n",
    "        To build required response in json format;\n",
    "            -  page level information:\n",
    "                    - page_no\n",
    "                    - page_width\n",
    "                    - page_height\n",
    "                    - images\n",
    "                    - tables\n",
    "                    - text_blocks\n",
    "            -  convert dataframe into proper json format:\n",
    "                    - img_df\n",
    "                    - text_df\n",
    "                    - tabel_df\n",
    "    '''\n",
    "    log_info(\"Service main\", \"document structure response started  ===>\", jobid)\n",
    "\n",
    "    response = { 'result' : [] }\n",
    "    for page_index, _ in enumerate(text_block_dfs):\n",
    "        #img_df     = img_dfs[page_index]\n",
    "        img_df     = bg_dfs[page_index]\n",
    "        text_df    = text_block_dfs[page_index]\n",
    "        table_df   = table_dfs[page_index]\n",
    "        line_df    = line_dfs[page_index]\n",
    "        page_json  = response_per_page(text_df, img_df, table_df,line_df, page_index, page_width, page_height)\n",
    "        response['result'].append(page_json)\n",
    "    \n",
    "    log_info(\"Service main\", \"document structure response successfully completed\", jobid)\n",
    "\n",
    "    return response\n",
    "\n",
    "def response_per_page(p_df, img_df, table_df,line_df,page_no,page_width,page_height):\n",
    "\n",
    "    p_df['block_id']     = range(len(p_df))\n",
    "    img_df['image_id']   = range(len(img_df))\n",
    "    table_df['table_id'] = range(len(table_df))\n",
    "    line_df['line_id']   = range(len(line_df))\n",
    "\n",
    "    res_dict           = {'page_no': page_no,'page_width': page_width,'page_height':page_height,'lines':[],'tables':[],'images':[],'text_blocks':[]}\n",
    "    image_data         = process_image_df(img_df)\n",
    "    table_data         = process_table_df(table_df)\n",
    "    line_data          = process_line_df(line_df)\n",
    "    text_data          = df_to_json(p_df)\n",
    "    res_dict['images'] = image_data\n",
    "    res_dict['tables'] = table_data\n",
    "    res_dict['lines']  = line_data\n",
    "    res_dict['text_blocks'] = text_data\n",
    "\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-08 20:22:02,283] {loghandler.py:20} MainThread INFO in loghandler: created processing directories successfully\n",
      "[2020-09-08 20:22:04,186] {loghandler.py:20} MainThread INFO in loghandler: Extracting xml of /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02.pdf\n",
      "[2020-09-08 20:22:05,153] {loghandler.py:20} MainThread INFO in loghandler: Extracting background images of /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02.pdf\n",
      "[2020-09-08 20:22:05,157] {loghandler.py:20} MainThread INFO in loghandler: Extraction of /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02.pdf completed in 2.8729329109191895\n",
      "Total number of pages (4) in file (Madras_HC_02.xml)\n",
      "Total number of pages (4) in file (Madras_HC_02.xml)\n",
      "[2020-09-08 20:22:05,318] {loghandler.py:20} MainThread INFO in loghandler: process_input_pdf: created dataframes successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/preprocess.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['text_right']  = sub_df['text_left'] + sub_df['text_width']\n",
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/preprocess.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub_df['text_bottom'] = sub_df['text_top'] + sub_df['text_height']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-08 20:22:05,780] {loghandler.py:20} MainThread INFO in loghandler: document structure analysis started  ===>\n",
      "[2020-09-08 20:22:05,780] {loghandler.py:20} MainThread INFO in loghandler: TableExtractor service started\n",
      "[2020-09-08 20:22:06,020] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:22:06,283] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-1.jpg\n",
      "[2020-09-08 20:22:07,001] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:22:07,235] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-2.jpg\n",
      "[2020-09-08 20:22:07,786] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:22:07,932] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-3.jpg\n",
      "[2020-09-08 20:22:08,344] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:22:08,483] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naresh/.local/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-08 20:22:10,063] {loghandler.py:20} MainThread INFO in loghandler: Extraction of h_dfs completed in 0.9594354629516602\n",
      "[2020-09-08 20:22:10,399] {loghandler.py:20} MainThread INFO in loghandler: Extraction of v_dfs completed in 0.3329331874847412\n",
      "[2020-09-08 20:22:11,048] {loghandler.py:20} MainThread INFO in loghandler: Extraction of p_dfs completed in 0.6447489261627197\n",
      "[2020-09-08 20:22:11,641] {loghandler.py:20} MainThread INFO in loghandler: UnderLineDetection successfully completed\n",
      "[2020-09-08 20:22:12,192] {loghandler.py:20} MainThread INFO in loghandler: Updating of fonts completed in 0.5442724227905273\n",
      "[2020-09-08 20:22:12,196] {loghandler.py:20} MainThread INFO in loghandler: tesseract ocr started  ===>\n",
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-1.jpg\n",
      " ग\n",
      " BEFORE THE MADURAI BENCH OF MADRAS HIGH COURT\n",
      " DATED: 26.02.2020\n",
      " CORAM:\n",
      " THE HONOURABLE MR.JUSTICE A.D.JAGADISH CHANDIRA\n",
      " Cont.P(MD)No.223 of 2020\n",
      " in\n",
      " (व.00.0 (0ना))१०.]0790 0 2049\n",
      " R.Jayaraj\n",
      " : Petitioner\n",
      " Vs.\n",
      " Malaisamy,\n",
      " Inspector of Police,\n",
      " Thallakulam Police Station,\n",
      " Thallakulam, Madurai.\n",
      " : Respondent\n",
      " PRAYER: Contempt Petition filed under Section of the Contempt of Court Act, to punish the contemnor / respondent herein for committing grave contempt and gross disobedience of the order passed by this Court in Crl.O.P(MD)No.l0790 of 209 dated 3.07.209.\n",
      " For Petitioner\n",
      " : Mr.M.M.Manivel Pandian\n",
      " For Respondent\n",
      " : Mr.S.Chandrasekar,\n",
      " Additional Public Prosecutor.\n",
      " http://www. judis.nic.in\n",
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-2.jpg\n",
      " 2.0\n",
      " ORDER\n",
      " This contempt petition has been filed to punish the contemnor / respondent herein for committing grave contempt and gross disobedience of the order passed by..this Court in Crl.O.P.(MD) No.i0790 of 209 dated 3i.07.209.\n",
      " 2.Contemnor is*present before this Court, today. The learned Additional Public Prosecutor appearing for the respondent would submit that-this Court by an order dated 3.07.20i9, had directed the police to-complete the investigation in Crime No.223 of 209 and file a final report within a period of one month from the date of receipt of copy of the order. The order copy was received by the respondent police on 05.42,.209 and immediately, steps were taken by respondent police and investigation has been completed and final report has been filed referring the case as mistake of fact. He would submit that RCS notice was also pasted on the house of the petitioner and that the order of this Court has been complied with. However, there was a delay on the part of the respondent police. He would submit that the delay is not willful and that the respondent police expressed his remorse for the delay in filing final report and he seeks apologies of this Court.\n",
      " http://www. judis.nic.in\n",
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-3.jpg\n",
      " 3.0\n",
      " 3.Apologies accepted. In view of the above, the alleged delay and disobedience cannot be termed as wilful disobedience of the order. Accordingly, this contempt petition stands closed. However, liberty is granted to the petitioner to challenge the final report.\n",
      " 26.02.2020\n",
      " Index: Yes/No\n",
      " Internet: Yes/No\n",
      " gns\n",
      " To\n",
      " । .नव8ां58ाएप,\n",
      " Inspector of Police,\n",
      " Thallakulam Police Station, Thallakulam, Madurai.\n",
      " 2.The Additional Public Prosecutor,\n",
      " Madurai Bench of Madras High Court, Madurai.\n",
      " http://www. judis.nic.in\n",
      "/home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_daba3830-f1e2-11ea-bda7-38baf82f7425/images/Madras_HC_020001-4.jpg\n",
      " 4.0\n",
      " A.D.JAGADISH CHANDIRA, J., gns\n",
      " (:070..7 (५)) द०.:] 23 0 2020\n",
      " 26.02.2020\n",
      " http://www. judis.nic.in\n",
      "[2020-09-08 20:22:41,914] {loghandler.py:20} MainThread INFO in loghandler: tesseract ocr successfully completed in 29.71445894241333\n",
      "[2020-09-08 20:22:41,915] {loghandler.py:20} MainThread INFO in loghandler: document structure analysis successfully completed\n",
      "CPU times: user 7.22 s, sys: 335 ms, total: 7.56 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pdf_filepath      = os.path.join(input_dir, filename)\n",
    "jobid             = 'JOBID_1000'\n",
    "lang              = 'hi'\n",
    "\n",
    "img_dfs, xml_dfs, page_width, page_height, working_dir, pdf_bg_img_filepaths,pdf_image_paths = get_xml.process_input_pdf(pdf_filepath, output_dir, lang)\n",
    "\n",
    "header_region, footer_region = prepocess_pdf_regions(xml_dfs, page_height,config.PREPROCESS_CONFIGS)\n",
    "pages          = len(xml_dfs)\n",
    "if pages > 1:\n",
    "    multiple_pages =True\n",
    "        \n",
    "text_block_dfs, table_dfs, line_dfs, bg_dfs = doc_structure_analysis(xml_dfs,img_dfs,working_dir,header_region , footer_region, lang, page_width, page_height, pdf_bg_img_filepaths,pdf_image_paths)\n",
    "# response   =  doc_structure_response(pages, bg_dfs, text_block_dfs, table_dfs,line_dfs,page_width, page_height,jobid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-08 20:17:45,999] {loghandler.py:20} MainThread INFO in loghandler: TableExtractor service started\n",
      "[2020-09-08 20:17:46,012] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:17:46,092] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_312860f8-f1e2-11ea-be75-38baf82f7425/pdftohtml/html/Madras_HC_02001.png\n",
      "[2020-09-08 20:17:46,189] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:17:46,244] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_312860f8-f1e2-11ea-be75-38baf82f7425/pdftohtml/html/Madras_HC_02002.png\n",
      "[2020-09-08 20:17:46,323] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:17:46,379] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_312860f8-f1e2-11ea-be75-38baf82f7425/pdftohtml/html/Madras_HC_02003.png\n",
      "[2020-09-08 20:17:46,474] {loghandler.py:110} MainThread ERROR in loghandler: Service TableExtractor Error in masking bg image\n",
      "[2020-09-08 20:17:46,532] {line.py:40} MainThread DEBUG in line: /home/naresh/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/notebooks/sample-data/input/Madras_HC_02_312860f8-f1e2-11ea-be75-38baf82f7425/pdftohtml/html/Madras_HC_02004.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naresh/.local/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-08 20:17:47,450] {loghandler.py:20} MainThread INFO in loghandler: Extraction of h_dfs completed in 0.8035352230072021\n",
      "[2020-09-08 20:17:47,629] {loghandler.py:20} MainThread INFO in loghandler: Extraction of v_dfs completed in 0.17785286903381348\n",
      "[2020-09-08 20:17:47,970] {loghandler.py:20} MainThread INFO in loghandler: Extraction of p_dfs completed in 0.3402590751647949\n"
     ]
    }
   ],
   "source": [
    "in_dfs, table_dfs, line_dfs,bg_dfs = get_text_table_line_df(xml_dfs, img_dfs, pdf_bg_img_filepaths)\n",
    "h_dfs                              = get_xml.get_hdfs(in_dfs,header_region,footer_region)\n",
    "v_dfs                              = get_xml.get_vdfs(h_dfs)\n",
    "p_dfs                              = get_xml.get_pdfs(v_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.services import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str or bytes, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dceee23f98cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -p {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocumentStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hi\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/project/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/main.py\u001b[0m in \u001b[0;36mDocumentStructure\u001b[0;34m(jobid, file_name, lang, base_dir)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mDocumentStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mimg_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader_region\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfooter_region\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiple_pages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_image_paths\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdoc_pre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjobid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mtext_blocks_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/project/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/main.py\u001b[0m in \u001b[0;36mdoc_pre_processing\u001b[0;34m(filename, base_dir, jobid)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Service main\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"document preprocessing started  ===>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mimg_dfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxml_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworking_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf_image_paths\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mget_xml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_input_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjobid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmultiple_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpages\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/project/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/get_xml.py\u001b[0m in \u001b[0;36mprocess_input_pdf\u001b[0;34m(filename, base_dir, jobid)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mxml_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_xml_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_xml_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mlog_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Service get_xml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error in extracting text xml info\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjobid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/project/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/services/get_xml.py\u001b[0m in \u001b[0;36mextract_pdf_metadata\u001b[0;34m(filename, working_dir, base_dir, jobid)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mextract\u001b[0m \u001b[0mfollowing\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;34m-\u001b[0m \u001b[0mimages\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;34m-\u001b[0m \u001b[0mbackground\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mpresent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meach\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     '''\n",
      "\u001b[0;32m~/Workspace/project/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/src/utilities/xml_utils.py\u001b[0m in \u001b[0;36mread_directory_files\u001b[0;34m(path, pattern)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_specific_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_element_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cv3/lib/python3.5/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mgenericpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'join'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cv3/lib/python3.5/genericpath.py\u001b[0m in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             raise TypeError('%s() argument must be str or bytes, not %r' %\n\u001b[0;32m--> 143\u001b[0;31m                             (funcname, s.__class__.__name__)) from None\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasstr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't mix strings and bytes in path components\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str or bytes, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "pdf_path   = os.path.join(input_dir, filename)\n",
    "save_path  = os.path.join(save_dir, str(filename.split('.pdf')[0]))\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.system('mkdir -p {0}'.format(save_path))\n",
    "data = main.DocumentStructure(100,filename, \"hi\",input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = data['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_image(draw,page_data):\n",
    "    \n",
    "    if page_data['images']:\n",
    "        try:\n",
    "            for image_block in page_data['images']:\n",
    "                    top     = image_block[\"text_top\"];         left   = image_block[\"text_left\"];  \n",
    "                    bottom  = top+image_block[\"text_height\"];  right  = left+image_block[\"text_width\"]\n",
    "                    draw.rectangle(((left, top), (right,bottom)), outline='green')\n",
    "            return draw\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_table(draw,page_data):\n",
    "    \n",
    "    if page_data['tables']:\n",
    "        try:\n",
    "            for table_block in page_data['tables']:\n",
    "                    top     = table_block[\"text_top\"];         left   = table_block[\"text_left\"];  \n",
    "                    bottom  = top+table_block[\"text_height\"];  right  = left+table_block[\"text_width\"]\n",
    "                    draw.rectangle(((left, top), (right,bottom)), outline='blue')\n",
    "            return draw\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_text(draw,page_data):\n",
    "    \n",
    "    if page_data['text_blocks']:\n",
    "        try:\n",
    "            for text_block in page_data['text_blocks']:\n",
    "                top     = text_block[\"text_top\"];         left   = text_block[\"text_left\"];  \n",
    "                bottom  = top+text_block[\"text_height\"];  right  = left+text_block[\"text_width\"]\n",
    "                draw.rectangle(((left, top), (right,bottom)), outline='red')\n",
    "            return draw\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_pdf(data,image_files,save_path):\n",
    "    for page_no in range(len(data)):\n",
    "        image_path = sorted(image_files)[page_no]\n",
    "        page_data = data[page_no]\n",
    "        page_width = page_data['page_width']; page_height = page_data['page_height']\n",
    "        image  = Image.open(image_path)\n",
    "        image  = image.resize((page_width, page_height))\n",
    "        draw   = ImageDraw.Draw(image)\n",
    "        draw  = draw_bbox_text(draw,page_data)\n",
    "        draw  = draw_bbox_image(draw,page_data)\n",
    "        draw  = draw_bbox_table(draw,page_data)\n",
    "        save_filepath = os.path.join(save_path,image_path.split('images/')[1])\n",
    "        image.save(save_filepath)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox_pdf(response,pdf_image_paths,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env2",
   "language": "python",
   "name": "ds-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
