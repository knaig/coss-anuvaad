{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "charged-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import config\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "def clean_image(image):\n",
    "\n",
    "     def HSV_mask(img_hsv, lower):\n",
    "          lower = np.array(lower)\n",
    "          upper = np.array([255, 255, 255])\n",
    "          return cv2.inRange(img_hsv, lower, upper)\n",
    "     \n",
    "     # img = cv2.imread(\"/home/srihari/Desktop/water_mark_issue/im/Gwalior_HC_page-0001.jpg\")\n",
    "     img = image\n",
    "\n",
    "     img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "     img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "     img_gray[img_gray >= 235] = 255\n",
    "\n",
    "     mask1 = HSV_mask(img_hsv, [0, 0, 155])[..., None].astype(np.float32)\n",
    "\n",
    "     mask2 = HSV_mask(img_hsv, [0, 20, 0])\n",
    "     masked = np.uint8((img + mask1) / (1 + mask1 / 255))\n",
    "\n",
    "\n",
    "\n",
    "     gray = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "     gray[gray >= 175] = 255\n",
    "\n",
    "\n",
    "     gray[mask2 == 0] = img_gray[mask2 == 0]\n",
    "\n",
    "     # clean = clean_image(gray)\n",
    "     gray = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "     image_id=str(uuid.uuid4())\n",
    "     cv2.imwrite(f\"/home/test/Tarento/anuvaad/anuvaad-etl/anuvaad-extractor/block-merger/upload/cleaned{image_id}.png\", gray)\n",
    "\n",
    "     return gray\n",
    "\n",
    "# def clean_image(image):\n",
    "#      image[config.WATERMARK_THRESHOLD_LOW < image ] = 255\n",
    "#      return image\n",
    "\n",
    "# def background_image(image):\n",
    "#      image[config.WATERMARK_THRESHOLD_LOW > image ] = 255\n",
    "#      return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retained-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.utilities.craft_pytorch.detect import detect_text_per_file as detect_text_per_page\n",
    "import cv2\n",
    "# import config\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.feature import canny\n",
    "#import time\n",
    "\n",
    "class Orientation:\n",
    "\n",
    "    def __init__(self, image_path,file_properties ,conf_threshold=50, lang='eng'):\n",
    "\n",
    "        self.image_path     = image_path\n",
    "        self.image          = cv2.imread(image_path)\n",
    "        self.file_properties = file_properties\n",
    "        # self.lines          = lines\n",
    "        self.conf_threshold = int(conf_threshold)\n",
    "\n",
    "        self.timer = {'net': 0, 'restore': 0, 'nms': 0}\n",
    "        self.text = {}\n",
    "        self.lang = lang\n",
    "\n",
    "        #self.re_orient()\n",
    "\n",
    "\n",
    "    def rotate_bound(self,image, angle):\n",
    "        # grab the dimensions of the image and then determine the\n",
    "        # center\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cX, cY) = (w / 2, h / 2)\n",
    "\n",
    "        # grab the rotation matrix (applying the negative of the\n",
    "        # angle to rotate clockwise), then grab the sine and cosine\n",
    "        # (i.e., the rotation components of the matrix)\n",
    "        M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)\n",
    "        cos = np.abs(M[0, 0])\n",
    "        sin = np.abs(M[0, 1])\n",
    "\n",
    "        # compute the new bounding dimensions of the image\n",
    "        nW = int((h * sin) + (w * cos))\n",
    "        nH = int((h * cos) + (w * sin))\n",
    "\n",
    "        # adjust the rotation matrix to take into account translation\n",
    "        M[0, 2] += (nW / 2) - cX\n",
    "        M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "        # perform the actual rotation and return the image\n",
    "        return cv2.warpAffine(image, M, (nW, nH),flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def east_detect(self,image,args): \n",
    "\n",
    "        #orig = image.copy()\n",
    "        (H, W) = image.shape[:2]\n",
    "\n",
    "        (newW, newH) = (args[\"width\"], args[\"height\"])\n",
    "        rW = W / float(newW)\n",
    "        rH = H / float(newH)\n",
    "\n",
    "        image = cv2.resize(image, (newW, newH))\n",
    "        (H, W) = image.shape[:2]\n",
    "\n",
    "        layerNames = [\n",
    "            \"feature_fusion/Conv_7/Sigmoid\",\n",
    "            \"feature_fusion/concat_3\"]\n",
    "\n",
    "        #print(\"[INFO] loading EAST text detector...\")\n",
    "        net = cv2.dnn.readNet(args[\"east\"])\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "            (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "        #start = time.time()\n",
    "        net.setInput(blob)\n",
    "        (scores, geometry) = net.forward(layerNames)\n",
    "        #end = time.time()\n",
    "\n",
    "        #print(\"[INFO] text detection took {:.6f} seconds\".format(end - start))\n",
    "    \n",
    "        # confidence scores\n",
    "        (numRows, numCols) = scores.shape[2:4]\n",
    "        angl = []\n",
    "\n",
    "        for y in range(0, numRows):\n",
    "            \n",
    "            scoresData = scores[0, 0, y]\n",
    "            anglesData = geometry[0, 4, y]\n",
    "\n",
    "            for x in range(0, numCols):\n",
    "                if scoresData[x] < args[\"min_confidence\"]:\n",
    "                    continue\n",
    "                \n",
    "                angle = anglesData[x]\n",
    "                angl.append(angle*180/(np.pi))\n",
    "\n",
    "        return np.median(angl)\n",
    "\n",
    "\n",
    "    def east(self,image_path,args):\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        angle = Orientation.east_detect(self,image,args)\n",
    "        #print(\"angle*********\",angle)\n",
    "\n",
    "        return image,angle\n",
    "\n",
    "\n",
    "    def hough_transforms(self,image):\n",
    "        \n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.GaussianBlur(gray,(11,11),0)\n",
    "        edges = canny(thresh)\n",
    "        tested_angles = np.deg2rad(np.arange(0.1, 180.0))\n",
    "        h, theta, d = hough_line(edges, theta=tested_angles)\n",
    "        accum, angles, dists = hough_line_peaks(h, theta, d)\n",
    "\n",
    "        return accum, angles, dists\n",
    "\n",
    "\n",
    "    def east_hough_line(self,image,args):\n",
    "        image,angle = Orientation.east(self,image,args)\n",
    "        h, theta, d = Orientation.hough_transforms(self,image)\n",
    "        theta = np.rad2deg(np.pi/2-theta)\n",
    "        #theta = np.rad2deg(theta-np.pi/2)\n",
    "        margin = args['margin_tollerance']\n",
    "        low_thresh = angle-margin\n",
    "        high_thresh = angle+margin\n",
    "        filter_theta = theta[theta>low_thresh]\n",
    "        filter_theta = filter_theta[filter_theta < high_thresh]\n",
    "        \n",
    "        return image,np.median(filter_theta)\n",
    "\n",
    "\n",
    "    def re_orient_east(self):\n",
    "        lang = 'hi'\n",
    "\n",
    "        args = {\n",
    "            \"image\": self.image_path,\n",
    "            \"east\": config.EAST_MODEL,\n",
    "            \"min_confidence\": config.MIN_CONFIDENCE,\n",
    "            \"margin_tollerance\":config.MARGIN_TOLLERANCE,\n",
    "            \"width\": config.EAST_WIDTH,\n",
    "            \"height\": config.EAST_HEIGHT\n",
    "        }\n",
    "\n",
    "        image,angle = Orientation.east_hough_line(self,args['image'],args)\n",
    "\n",
    "        if abs(angle) > config.ANGLE_TOLLERANCE:\n",
    "            image = Orientation.rotate_bound(self,image, angle)\n",
    "            #print(self.image_path)\n",
    "            #image_path = Orientation(self.image_path)\n",
    "            cv2.imwrite(self.image_path, image)\n",
    "\n",
    "        print(\"Angle detectd is  {} \".format(angle))\n",
    "\n",
    "        return image,angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abstract-gathering",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'routes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6297d23dfe4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblueprints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlueprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_cors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mroutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'routes'"
     ]
    }
   ],
   "source": [
    "from logging.config import dictConfig\n",
    "\n",
    "from flask import Flask\n",
    "from flask.blueprints import Blueprint\n",
    "from flask_cors import CORS\n",
    "import routes\n",
    "import config\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('file')\n",
    "tok_app  = Flask(__name__)\n",
    "\n",
    "if config.ENABLE_CORS:\n",
    "    cors    = CORS(tok_app, resources={r\"/api/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "for blueprint in vars(routes).values():\n",
    "    if isinstance(blueprint, Blueprint):\n",
    "        tok_app.register_blueprint(blueprint, url_prefix=config.API_URL_PREFIX)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tok_app.run(host=config.HOST, port=config.PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
