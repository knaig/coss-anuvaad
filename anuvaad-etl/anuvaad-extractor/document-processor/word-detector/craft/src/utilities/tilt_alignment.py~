from src.utilities.craft_pytorch.detect import detect_text_per_file as detect_text_per_page
import cv2
import config
import imutils
import pandas as pd
import numpy as np

class Orientation:

    def __init__(self, image_path,file_properties ,conf_threshold=50, lang='eng'):

        self.image_path     = image_path
        self.image          = cv2.imread(image_path)
        self.file_properties = file_properties
        # self.lines          = lines
        self.conf_threshold = int(conf_threshold)

        self.timer = {'net': 0, 'restore': 0, 'nms': 0}
        self.text = {}
        self.lang = lang

        #self.re_orient()




    def augment_df(self,df):
        # dic = []
        # for i,box in enumerate(self.bbox):
        # dic.append({'x1': box[0] ,'y1': box[1] ,'x2': box[2] ,'y2': box[3] ,'x3': box[4] ,'y3': box[5] ,'x4': box[6] ,'y4': box[7]})
        #df = pd.DataFrame(self.bbox, columns=['x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'x4', 'y4'])
        df['height'] = df['y4'] - df['y1']
        df['width'] = df['x2'] - df['x1']
        df['ymid'] = (df['y4'] + df['y3']) * 0.5
        df['area'] = df['width'] * df['height']
        df = df.sort_values(by=['ymid'])
        df['group'] = None
        df['line_change'] = 0
        return df

    def dump_out(self, bbc, rot):
        im = self.image.copy()
        for box in bbc:
            # print(box)
            cv2.polylines(im, [np.array(box).astype(np.int32).reshape((-1, 1, 2))], True, color=(255, 255, 0),
                          thickness=1)
        cv2.imwrite('tmp/' + str(rot) + '.png', im)

    def get_rotaion_angle(self, text_cor_df):

        bbox_df = text_cor_df.copy()
        bbox_df = self.augment_df(bbox_df)

        bbox_df['delta_x'] = bbox_df['x2'] - bbox_df['x1']
        bbox_df['delta_y'] = bbox_df['y2'] - bbox_df['y1']
        box_dir = [bbox_df['delta_x'].mean(), bbox_df['delta_y'].mean()]
        # print(box_dir)
        x_axis = [1, 0]
        try:
            cosine = np.dot(box_dir, x_axis) / (np.linalg.norm(box_dir) * np.linalg.norm(x_axis))
        except Exception as e:
            print('ERROR in finding angle of rotaion!!!')
            print(e)
            cosine = 1
        angle = np.arccos(cosine) * 180 / np.pi
        avrage_height = bbox_df['height'].mean()

        avrage_width = bbox_df['width'].mean()
        #if avrage_height > avrage_width:
        #    angle = 90 - angle

        return angle * np.sign(box_dir[1])



    def rotate_bound(self, image, angle):
        # grab the dimensions of the image and then determine the
        # center
        (h, w) = image.shape[:2]
        (cX, cY) = (w / 2, h / 2)

        # grab the rotation matrix (applying the negative of the
        # angle to rotate clockwise), then grab the sine and cosine
        # (i.e., the rotation components of the matrix)
        M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
        cos = np.abs(M[0, 0])
        sin = np.abs(M[0, 1])

        # compute the new bounding dimensions of the image
        nW = int((h * sin) + (w * cos))
        nH = int((h * cos) + (w * sin))

        # adjust the rotation matrix to take into account translation
        M[0, 2] += (nW / 2) - cX
        M[1, 2] += (nH / 2) - cY

        # perform the actual rotation and return the image
        return cv2.warpAffine(image, M, (nW, nH),flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)


    def re_orient(self):
        lang = 'hi'
        
        craft_config = self.file_properties.get_craft_config()

        if craft_config == None :
            text_threshold = config.LANGUAGE_LINE_THRESOLDS[lang]['text_threshold']
            low_text_threshold = config.LANGUAGE_LINE_THRESOLDS[lang]['low_text']
            link_threshold = config.LANGUAGE_LINE_THRESOLDS[lang]['link_threshold']
        else:
            text_threshold = craft_config['text_threshold']
            low_text_threshold = craft_config['low_text']
            link_threshold = craft_config['link_threshold']

        lines = detect_text_per_page([self.image], \
                                     network=True, \
                                     text_threshold=text_threshold, \
                                     low_text_threshold=low_text_threshold,
                                     link_threshold=link_threshold)[0]

        # words = detect_text_per_page([self.image], \
        #                              network=False, \
        #                              text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['text_threshold'], \
        #                              low_text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['low_text'],
        #                              link_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['link_threshold'])[0]



        angle = self.get_rotaion_angle(lines)
        #angle = self.get_rotaion_angle(words)
        print("Angle of tilt detected {} ".format(angle))

        if abs(angle) > 2.5:
            self.image = self.rotate_bound(self.image, -angle)

            lines = detect_text_per_page([self.image], \
                                         network=True, \
                                         text_threshold=text_threshold, \
                                         low_text_threshold=low_text_threshold,
                                         link_threshold=link_threshold)[0]
            
            cv2.imwrite(self.image_path, self.image)

        words = detect_text_per_page([self.image], \
                                    network=False, \
                                    text_threshold=text_threshold, \
                                    low_text_threshold=low_text_threshold,
                                    link_threshold=link_threshold)[0]
        angle = self.get_rotaion_angle(lines)
        print("Angle of tilt after correction {} ".format(angle))


        #lines = words

        return words, lines

    #
    # def re_orient(self):
    #     lang = 'hi'
    #     lines = detect_text_per_page([self.image],\
    #                                  network=True, \
    #                                  text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['text_threshold'], \
    #                                  low_text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['low_text'],
    #                                  link_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['link_threshold'])[0]
    #
    #     angle = self.get_rotaion_angle(lines)
    #     print("Angle of tilt detected {} ".format(angle) )
    #     rotations = 1
    #     # self.dump_out(lines,rotations)
    #     # Orientation correction
    #     if config.ALIGN_MODE == 'FAST':
    #      tolerance = 0.1
    #     if config.ALIGN_MODE == 'ACCURATE':
    #         tolerance = 0.1
    #
    #     while (abs(angle) > tolerance) and rotations < 3:
    #         self.image = self.rotate_bound(self.image, -angle)
    #
    #         if rotations > 1:
    #             # Remove rotaion artifacts
    #             contours = cv2.findContours(cv2.cvtColor(self.image, cv2.COLOR_BGR2GRAY), cv2.RETR_EXTERNAL,
    #                                         cv2.CHAIN_APPROX_SIMPLE)
    #             contours = contours[0] if len(contours) == 2 else contours[1]
    #             if len(contours) > 0:
    #                 x, y, w, h = cv2.boundingRect(contours[0])
    #                 # print('cropped area reduced ')
    #                 self.image = self.image[y:y + h, x:x + w, :]
    #
    #         lines = detect_text_per_page([self.image], \
    #                                      network=True, \
    #                                      text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['text_threshold'], \
    #                                      low_text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['low_text'],
    #                                      link_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['link_threshold'])[0]
    #         angle = self.get_rotaion_angle(lines)
    #         print("Angle of tilt after correction {} ".format(angle))
    #         rotations += 1
    #         # self.dump_out(east_cor,rotations)
    #     cv2.imwrite(self.image_path,self.image)
    #     words = detect_text_per_page([self.image], \
    #                                      network=False, \
    #                                      text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['text_threshold'], \
    #                                      low_text_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['low_text'],
    #                                      link_threshold=config.LANGUAGE_LINE_THRESOLDS[lang]['link_threshold'])[0]
    #     # if config.ALIGN_MODE not "FAST":
    #     #     upside_down = self.check_orientation(bbox1.gr_cordinates)
    #
    #
    #     return words, lines
    #

  # def check_orientation(self, group_cordinates, margin=5):
    #     upside_down = False
    #     orientation = []
    #     for index, block in enumerate(group_cordinates):
    #         crop = self.image[block[0][1] - margin: block[1][1] + margin,
    #                block[0][0] - margin: block[1][0] + margin]
    #         try:
    #             osd = pytesseract.image_to_osd(crop)
    #             angle = osd.split('\nRotate')[0].split(': ')[-1]
    #             orientation.append(int(angle))
    #         except:
    #             pass
    #     orientation = np.array(orientation)
    #     chk_orientation = orientation > 170
    #
    #     # Taking vote of regions
    #     if chk_orientation.sum() > (len(orientation) * 0.5):
    #         # print ('Image is upside down')
    #         upside_down = True
    #         return upside_down
    #
    #     return upside_down
    #
    #


