swagger: "2.0"
info:
  version: 1.0.0
  title: Anuvaad Sentence Tokeniser - Kafka Contract 
  description: A python based microservice to trigger and orchestrate the sentence tokenisation part of anuvaad-extractor. This service will expose REST APIs for workflow related activities on the other hand will also be plugged into the system as a consumer that picks records posted onto the Kafka Queue in order to perform workflow related activities.
  contact:
    name: Kumar Deepak
    email: kumar.deepak@tarento.com
    
    
usecase:
  intiate-html2json:
    input-topic: anuvaad-dp-tools-tokeniser-input
    description: In order to get the input for tokeniser tool asynchronously, the below mentioned JSON has to be listened from the above mentioned topic. The tokeniser will consume this data and trigger the tokeniser operation.
    $ref: '#/definitions/TokenisationRequest'
    
  complete-html2json:
    input-topic: anuvaad-dp-tools-tokeniser-output
    description: In order to get the output for tokeniser tool asynchronously, the below mentioned JSON has to be pushed to the above mentioned topic.
    $ref: '#/definitions/TokenisationResponse'
    
    
definitions:

  File:
    type: object
    properties:
      name:
        type: string
        description: In case of Input Filename, This will be obtained in the output of the file upload API exposed by the anuvaad system. 
                      In case of Output Filename, This will be generated by 13 digit epoch time. 
      type:
        type: string
        description: type of the file.
        enum:
          - TEXT
          - CSV
      locale:
        type: string
        description: The locale of the file. Meaning, in which language is the uploaded file. For instance, 'en' for English, 'hi' for Hindi etc.
        format: varchar
        
        
  FileInput:
    type: object
    properties:
      source:
        type: object
        description: Details of the source file.
        $ref: '#/definitions/File'        

        
  FileOutput:
    type: object
    properties:
      source:
        type: object
        description: Source Filename.
        $ref: '#/definitions/File/properties/name'        
      target:
        type: object
        description: Target Filename.
        $ref: '#/definitions/File/properties/name'
        
      
  TokenisationRequest:
    type: object
    properties:
      input:
        type: object
        description: Details of the source files of which tokenised sentence has to be generated.
        $ref: '#/definitions/FileInput'
      jobID:   
        type: string
        description: A unique job ID generated for complete workflow. i.e.received from previous operation.  
      state:
        type: string
        description: current state of workflow received from previous operation.
        enum:
          - INITIATED
      status:
        type: string
        description: current status of workflow received from previous operation.
        enum:
          - STARTED
      workflowCode:
        type: string
        description: Received from previous operation. Code of the workflow that has to be picked to process this input.
                      These workflows are configured at the application level.
      tool:
        type: string
        description: Current tool name.
        enum:
          - TOKENISER
      stepOrder:
        type: integer
        description: Current steporder of workflow received from previous operation.

        
  TokenisationResponse:
    type: object
    properties:        
      jobID:
        type: string
        description: A unique job ID generated for the complete workflow.
      taskID:
        type: string
        description: A unique task ID generated for the current on-going task of the tokeniser.
      status:
        type: string
        description: Current status of the tokenisation part of workflow.
        enum:
          - SUCCESS
          - FAILED
      state:
        type: string
        description: Current state of the tokenisation part of workflow.
        enum:
          - SENTENCE-TOKENISED
      output:
        type: object
        description: Final output of this process.
        $ref: '#/definitions/FileOutput'
      workflowCode:
        type: string
        description: Received from previous operation. Code of the workflow that has to be picked to process this input.
                      These workflows are configured at the application level.
      tool:
        type: string
        description: Current tool name.
        enum:
          - TOKENISER
      stepOrder:
        type: integer
        description: Current steporder of workflow received from previous operation.
      error:
        type: object
        description: Incase the job fails due to an error in of the child tasks, that error will be capture here for the benefit of the user.
        $ref: '#/definitions/Error'
      startTime:
        type: number
        description: 13 digit epoch of the start time.
      endTime:
        type: number
        description: 13 digit epoch of the end time.

        
        
  Error:
    type: object
    properties:
      jobID:
        type: string
        description: ID of the job within which the error occured.
      taskID:
        type: string
        description: ID of the task within which the error occured.
      state:
        type: string
        description: Processing state of the job just before the error.
      workflowCode:
        type: string
        description: Received from previous operation. Code of the workflow that has to be picked to process this input.
                      These workflows are configured at the application level.
      error:
        type: object
        properties:
          code:
            type: string
            description: This is the cause of the error.
          message:
            type: string
            description: User understandable message.
      startTime:
        type: number
        description: 13 digit epoch of the start time.
      endTime:
        type: number
        description: 13 digit epoch of the end time.